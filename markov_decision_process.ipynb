{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ea3a0d",
   "metadata": {},
   "source": [
    "# Optimisation Exercise\n",
    "# Thomas GRAHAM - Adam HAMI - Lucas GOUTODIER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88643f",
   "metadata": {},
   "source": [
    "## 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c7c31",
   "metadata": {},
   "source": [
    "## 2)\n",
    "\n",
    "We have decided to consider the policy  \n",
    "\\[ D^* = (N, M, M, C, C, C) \\]  \n",
    "for the states 1 to 6 respectively.\n",
    "\n",
    "### 2a) Construction of \\(P(D^*)\\)\n",
    "\n",
    "To construct \\(P(D^*)\\) we apply the rules of \\(D^*\\) to the original transition matrix:\n",
    "\n",
    "- **Row 1**: action **N** → no action taken, keep row 1  \n",
    "- **Row 2**: action **M** → state 2 moves to state 1  \n",
    "- **Row 3**: action **M** → state 3 moves to state 2  \n",
    "- **Row 4**: action **C** → state 4 moves to state 1  \n",
    "- **Row 5**: action **C** → state 5 moves to state 2  \n",
    "- **Row 6**: action **C** → state 6 moves to state 3  \n",
    "\n",
    "Therefore,\n",
    "\n",
    "\\[\n",
    "P(D^*) =\n",
    "\\begin{bmatrix}\n",
    "0.60 & 0.25 & 0.05 & 0.05 & 0.03 & 0.02 \\\\\n",
    "1.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
    "0.00 & 1.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
    "1.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
    "0.00 & 1.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n",
    "0.00 & 0.00 & 1.00 & 0.00 & 0.00 & 0.00\n",
    "\\end{bmatrix}.\n",
    "\\]\n",
    "\n",
    "### 2b) Stationary distribution\n",
    "\n",
    "Let pi = (pi1, pi2, pi3, pi4, pi5, pi6).\n",
    "\n",
    "It satisfies:\n",
    "\n",
    "pi = pi P(D*)  \n",
    "Sum(pi_i) = 1\n",
    "\n",
    "Because rows 2 to 6 are deterministic, the balance equations are:\n",
    "\n",
    "pi4 = 0.05 pi1  \n",
    "pi5 = 0.03 pi1  \n",
    "pi6 = 0.02 pi1  \n",
    "\n",
    "pi3 = 0.05 pi1 + pi6 = 0.07 pi1  \n",
    "\n",
    "pi2 = 0.25 pi1 + pi3 + pi5 = 0.35 pi1  \n",
    "\n",
    "Using the normalization condition:\n",
    "\n",
    "pi1 + 0.35 pi1 + 0.07 pi1 + 0.05 pi1 + 0.03 pi1 + 0.02 pi1 = 1  \n",
    "\n",
    "1.52 pi1 = 1  \n",
    "\n",
    "pi1 = 1 / 1.52 = 0.65789474\n",
    "\n",
    "Substituting:\n",
    "\n",
    "pi2 = 0.23026316  \n",
    "pi3 = 0.04605263  \n",
    "pi4 = 0.03289474  \n",
    "pi5 = 0.01973684  \n",
    "pi6 = 0.01315789  \n",
    "\n",
    "Therefore,\n",
    "\n",
    "pi(D*) ≈ (0.65789474, 0.23026316, 0.04605263, 0.03289474, 0.01973684, 0.01315789)\n",
    "\n",
    "\n",
    "### 2c) Long-run expected cost\n",
    "\n",
    "The immediate costs are:\n",
    "\n",
    "State 1, N = 0  \n",
    "State 2, M = 40  \n",
    "State 3, M = 60  \n",
    "State 4, C = 50  \n",
    "State 5, C = 70  \n",
    "State 6, C = 80  \n",
    "\n",
    "The long-run expected cost is:\n",
    "\n",
    "E[C(D*)] = Sum( pi_i x C(i, d_i) )\n",
    "\n",
    "E[C(D*)] =\n",
    "0.65789474 x 0\n",
    "+ 0.23026316 x 40\n",
    "+ 0.04605263 x 60\n",
    "+ 0.03289474 x 50\n",
    "+ 0.01973684 x 70\n",
    "+ 0.01315789 x 80\n",
    "\n",
    "E[C(D*)] ≈ 16.05263\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44345f78",
   "metadata": {},
   "source": [
    "## 3)\n",
    "\n",
    "The feasible actions in each state are:\n",
    "\n",
    "State 1: {N}  \n",
    "State 2: {N, M}  \n",
    "State 3: {N, M}  \n",
    "State 4: {N, C}  \n",
    "State 5: {N, C, M}  \n",
    "State 6: {C, M, R}\n",
    "\n",
    "This yields:\n",
    "\n",
    "1 x 2 x 2 x 2 x 3 x 3 = 72\n",
    "\n",
    "feasible stationary policies.\n",
    "\n",
    "Procedure:\n",
    "\n",
    "For each feasible policy D:\n",
    "\n",
    "1) Construct the transition matrix P(D)  \n",
    "2) Solve pi = pi P(D) with Sum(pi_i) = 1  \n",
    "3) Compute the long-run average cost\n",
    "\n",
    "E[C(D)] = Sum( pi_i(D) x C(i, d_i) )\n",
    "\n",
    "All 72 policies were evaluated programmatically.\n",
    "\n",
    "The policy with the minimum long-run average cost is:\n",
    "\n",
    "D_opt = (N, M, M, C, C, C)\n",
    "\n",
    "with:\n",
    "\n",
    "E[C(D_opt)] ≈ 16.05263\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ad05a",
   "metadata": {},
   "source": [
    "## 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f0dd3",
   "metadata": {},
   "source": [
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409b042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: {1: 'N', 2: 'M', 3: 'N', 4: 'C', 5: 'C', 6: 'C'}\n",
      "Generations: 100000\n",
      "Total cost: 1651240\n",
      "Average long-run cost: 16.5124\n"
     ]
    }
   ],
   "source": [
    "# Modify the policy and number of generations here\n",
    "policy = {\n",
    "    1: 'N',\n",
    "    2: 'M',\n",
    "    3: 'N',\n",
    "    4: 'C',\n",
    "    5: 'C',\n",
    "    6: 'C'\n",
    "}\n",
    "\n",
    "generations = 100000\n",
    "\n",
    "import random\n",
    "\n",
    "P = [\n",
    "    [0.60, 0.25, 0.05, 0.05, 0.03, 0.02],\n",
    "    [0.20, 0.50, 0.20, 0.03, 0.05, 0.02],\n",
    "    [0.10, 0.30, 0.40, 0.05, 0.10, 0.05],\n",
    "    [0.15, 0.10, 0.05, 0.45, 0.20, 0.05],\n",
    "    [0.05, 0.10, 0.15, 0.15, 0.45, 0.10],\n",
    "    [0.02, 0.05, 0.10, 0.08, 0.15, 0.60]\n",
    "]\n",
    "\n",
    "costs = {\n",
    "    1: {'N': 0},\n",
    "    2: {'N': 20, 'M': 40},\n",
    "    3: {'N': 40, 'M': 60},\n",
    "    4: {'N': 20, 'C': 50},\n",
    "    5: {'N': 110, 'C': 70, 'M': 100},\n",
    "    6: {'C': 80, 'M': 120, 'R': 2000}\n",
    "}\n",
    "\n",
    "action_transition = {\n",
    "    (2, 'M'): 1,\n",
    "    (3, 'M'): 2,\n",
    "    (4, 'C'): 1,\n",
    "    (5, 'C'): 2,\n",
    "    (5, 'M'): 4,\n",
    "    (6, 'C'): 3,\n",
    "    (6, 'M'): 5,\n",
    "    (6, 'R'): 1\n",
    "}\n",
    "\n",
    "current_state = 1\n",
    "total_cost = 0\n",
    "\n",
    "for _ in range(generations):\n",
    "    action = policy[current_state]\n",
    "    total_cost += costs[current_state][action]\n",
    "\n",
    "    if action == 'N':\n",
    "        r = random.random()\n",
    "        cumulative = 0\n",
    "        for next_state, prob in enumerate(P[current_state - 1], start=1):\n",
    "            cumulative += prob\n",
    "            if r <= cumulative:\n",
    "                current_state = next_state\n",
    "                break\n",
    "    else:\n",
    "        current_state = action_transition[(current_state, action)]\n",
    "\n",
    "average_cost = total_cost / generations\n",
    "\n",
    "print(\"Policy:\", policy)\n",
    "print(\"Generations:\", generations)\n",
    "print(\"Total cost:\", total_cost)\n",
    "print(\"Average long-run cost:\", average_cost)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
